from ultralytics import YOLO
import cv2
import numpy as np

# âœ… YOLOv8 ëª¨ë¸ ê²½ë¡œ ì„¤ì • / Set YOLOv8 model paths
MODEL_PATHS = {
    "braille": "../models/braille.pt",
    "crosswalk": "../models/crosswalk.pt",
    "traffic": "../models/traffic.pt",
}
models = {k: YOLO(v) for k, v in MODEL_PATHS.items()}  # ê° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° / Load each YOLO model

# ğŸ”„ Bâ†”R ì±„ë„ ìŠ¤ì™‘ í•¨ìˆ˜ / Swap Blue and Red channels in image
# ESP32-CAMì˜ ë¹¨ê°„ìƒ‰ì´ íŒŒë€ìƒ‰ìœ¼ë¡œ ë³´ì´ëŠ” ì´ìŠˆë•Œë¬¸ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.
def swap_blue_red_channel(img_bgr):
    return img_bgr[:, :, ::-1].copy()

# âœ… ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ / Main image analysis function
def analyze_image(image_path):
    img = cv2.imread(image_path)  # ì´ë¯¸ì§€ ì½ê¸° / Read image file

    # ğŸ”„ ìƒ‰ìƒ ë°˜ì „ ëŒ€ì‹  Bâ†”R ì±„ë„ êµí™˜ / Swap B and R channels instead of invert
    img = swap_blue_red_channel(img)

    # YOLO ì…ë ¥ìš© RGB ë³€í™˜ / Convert image to RGB for YOLO input
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # ğŸ” YOLOë¡œ íš¡ë‹¨ë³´ë„/ì‹ í˜¸ë“± ì¶”ë¡  / Run YOLO inference (crosswalk, traffic)
    crosswalk_result = models["crosswalk"](img_rgb)
    traffic_result = models["traffic"](img_rgb)

    # ì˜ˆì¸¡ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥(ë””ë²„ê¹…ìš©) / Save inference result for debugging
    traffic_result[0].save("output.jpg")

    # íš¡ë‹¨ë³´ë„ ë°•ìŠ¤ ê°ì§€ / Detect crosswalk boxes
    boxes = crosswalk_result[0].boxes
    has_crosswalk = len(boxes) > 0

    crosswalk_area = None
    if has_crosswalk:
        # ê°€ì¥ í° ë°•ìŠ¤ ì„ íƒ / Select biggest crosswalk box
        biggest_box = max(
            boxes,
            key=lambda b: (b.xyxy[0][2] - b.xyxy[0][0]) * (b.xyxy[0][3] - b.xyxy[0][1])
        )
        crosswalk_area = biggest_box.xyxy[0].cpu().numpy()

    # ì‹ í˜¸ë“± ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ / Extract class names from traffic results
    traffic_classes = [
        traffic_result[0].names[int(c)].lower()
        for c in traffic_result[0].boxes.cls.cpu().numpy()
    ]
    print("ğŸ”¥ ê°ì§€ëœ í´ë˜ìŠ¤:", traffic_classes)

    # ì‹ í˜¸ë“± ìƒíƒœ íŒë‹¨ / Judge traffic light state
    has_red = any("traffic light-red-" in cls for cls in traffic_classes)
    has_green = any("traffic light-green-" in cls for cls in traffic_classes)

    if has_red and has_green:
        traffic_label = "âš ï¸ ë¹¨ê°„ë¶ˆê³¼ ì´ˆë¡ë¶ˆì´ ë™ì‹œì— ê°ì§€ë¨"  # ë‘˜ ë‹¤ ê°ì§€ ì‹œ / Both detected
    elif has_red:
        traffic_label = "ë¹¨ê°„ë¶ˆ"  # ë¹¨ê°„ë¶ˆ ê°ì§€ / Red detected
    elif has_green:
        traffic_label = "ì´ˆë¡ë¶ˆ"  # ì´ˆë¡ë¶ˆ ê°ì§€ / Green detected
    else:
        traffic_label = ""  # ê°ì§€ëœ ì‹ í˜¸ë“± ì—†ìŒ / No light detected

    print("ğŸš¦ íŒë‹¨ëœ ì‹ í˜¸ë“± ìƒíƒœ:", traffic_label)

    # íš¡ë‹¨ë³´ë„ ìœ„ ê°ì²´ íƒì§€ / Detect objects on crosswalk
    objects_on_crosswalk = []
    if crosswalk_area is not None:
        x1, y1, x2, y2 = crosswalk_area
        for box in traffic_result[0].boxes:
            cls = traffic_result[0].names[int(box.cls[0])].lower()
            if cls in ["person", "car", "truck", "bus"]:
                bx1, by1, bx2, by2 = box.xyxy[0].cpu().numpy()
                cx, cy = (bx1 + bx2) / 2, (by1 + by2) / 2
                if x1 <= cx <= x2 and y1 <= cy <= y2:
                    objects_on_crosswalk.append(cls)  # ì¤‘ì‹¬ì ì´ íš¡ë‹¨ë³´ë„ ë‚´ë¶€ë©´ ì¶”ê°€ / Add if center in crosswalk

    # ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜ / Return results as dictionary
    return {
        "has_crosswalk": has_crosswalk,
        "traffic_label": traffic_label,
        "objects_on_crosswalk": objects_on_crosswalk
    }
